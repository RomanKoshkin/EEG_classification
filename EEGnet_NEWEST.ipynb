{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: NeoRec_2018-05-08_21-47-10+ICA.mat, DS2=64Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-123.mat\n",
      "Download Progress: 100\n",
      "Download Complete\n"
     ]
    }
   ],
   "source": [
    "from URL_download_2 import gdown\n",
    "# file_id = '13fwf4uud01MVUh4bjZNiVXSaFRAH67vS'\n",
    "# file_id = '1SlN6eSUcGIIxWPELZfYtxprb0bCjjp8f'\n",
    "file_id = '1Kzs5d8KA9JXPwb37kZ6obkcQGAAGWDcE'\n",
    "\n",
    "# instantiate class (create a class instance):\n",
    "G = gdown()\n",
    "\n",
    "# Download data from Google Drive as necessary:\n",
    "G.download_file(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'EEG_big.mat'\n",
    "# file = 'EEG_big4CNN.mat'\n",
    "# file = 'EEG_big4CNN_1subj.mat'\n",
    "# file = 'KOS_100Hz_noICA->0.5-38Hz,Env=1.mat' #0.60 (EEGnet.v2)\n",
    "\n",
    "# file = 'KOS_100Hz_ICA->0.5-38Hz,Env=1.mat' #0.50 (EEGnet.v2)\n",
    "# file = 'Merged123->1-48Hz,Env=1.mat'\n",
    "\n",
    "# file = 'BCI_TD.mat'\n",
    "\n",
    "# file = 'BCI_0101T_TD.mat'\n",
    "# file = 'BCI_0202T_TD.mat'\n",
    "# file = 'BCI_0303T_TD.mat'\n",
    "# file = 'BCI_0403T_TD.mat'\n",
    "# file = 'BCI_0503T_TD.mat'\n",
    "# file = 'BCI_0603T_TD.mat'\n",
    "# file = 'BCI_0703T_TD.mat'\n",
    "# file = 'BCI_0801T_TD.mat'\n",
    "\n",
    "# file = 'BCI_FD.mat'\n",
    "\n",
    "# file = 'ks.mat'\n",
    "# file = 'ks_FD.mat'\n",
    "# file = 'ks_2TD.mat'\n",
    "# file = 'ksenia2_long_chunked.mat'\n",
    "\n",
    "# file = 'BCI_FD_fullspectrum.mat'\n",
    "# file = 'BCI_FD_lowspectrum.mat'\n",
    "# file = 'KOS_100Hz_ICA->1-38Hz,Env=1_FD.mat'\n",
    "# file = 'Merged123->1-100Hz,Env=1_FD'\n",
    "# file = 'Merged123->1-47Hz,Env=1_FD.mat'\n",
    "# file = 'Merged123->15-47Hz,Env=1_TD.mat'\n",
    "# file = 'Merged123->15-47Hz,Env=1_TD5_64_.mat'\n",
    "# file = 'Merged123->75-134Hz,Env=1_TD.mat'\n",
    "# file = 'Merged123->2-30Hz,Env=1_TD5_64_.mat'\n",
    "\n",
    "# file = 'Merged456->2-30Hz,Env=1_TD1_94_.mat'                # 0.71 0.63(EEGnet.v2)\n",
    "# file = 'Merged456->2-30Hz,Env=1_TD101_192_.mat'             # 0.60(1D) 0.58(EEGnet.v2)\n",
    "# file = 'Merged456->2-30Hz,Env=1_TD197_289_.mat'             # 0.90(1D) 0.87(EEGnet.v2)\n",
    "\n",
    "# file = 'DAS_1_ica.mat, DS2=200Hz, FIR=1-60Hz, centnorm=1, Env=1, ICA, 1-124.mat' # 0.53 \n",
    "# file = 'Merged456_197-298_protocol_1.set, DS2=250Hz, FIR=1-47Hz, centnorm=0, Env=0, ICA, 1-95.mat'\n",
    "# file = 'Merged456_197-298_protocol_1.set, DS2=250Hz, FIR=1-47Hz, centnorm=0, Env=0, NOICA, 1-95.mat'\n",
    "\n",
    "\n",
    "\n",
    "# file = 'DAS_CH.mat, DS2=250Hz, FIR=1-30Hz, centnorm=1, Env=1, TD, 1-124.mat' # 0.65 #0.54(EEGnet.v2)\n",
    "# file = 'DAS_CH.mat, DS2=250Hz, FIR=1-38Hz, centnorm=1, Env=1, TD, 1-124.mat'\n",
    "# file = 'DAS_CH.mat, DS2=250Hz, FIR=1-47Hz, centnorm=1, Env=1, TD, 1-124.mat'   # 0.60\n",
    "# file = 'NeoRec_2018-05-08_21-47-10+ICA(-IC1)preproc_aud.mat, DS2=64Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-123.mat'   #0.62(EEGnet.v2)\n",
    "# file = 'NeoRec_2018-05-08_21-47-10+ICA(-IC1)preproc_aud.mat, DS2=128Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-123.mat'  #0.63(EEGnet.v2)\n",
    "# file = 'NeoRec_2018-05-08_21-47-10+ICA.mat, DS2=64Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-123.mat' #0.66 #0.64(EEGnet.v2)\n",
    "# file = 'NeoRec_2018-05-08_16-52-10_-eyes.mat, DS2=64Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-124.mat' #0.51(EEGnet.v2)\n",
    "# file = 'NeoRec_2018-05-08_16-52-10_-eyes.mat, DS2=128Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-124.mat'  #0.49(EEGnet.v2)\n",
    "# file = 'NeoRec_2018-05-08_16-52-10.mat, DS2=64Hz, FIR=1-40Hz, centnorm=1, Env=1, TD, 1-124.mat' #0.47(EEGnet.v2)\n",
    "\n",
    "# file = 'Merged123_1_64_ICA(-eyes)AUDpreproc.mat, DS2=64Hz, FIR=1-9Hz, centnorm=1, Env=1, TD, 1-90.mat'\n",
    "# file = 'Merged123_1_64_ICA(-eyes)AUDpreproc.mat, DS2=250Hz, FIR=2-30Hz, centnorm=1, Env=1, TD, 1-90.mat' # 0.61\n",
    "# file = 'Merged123_1_64_ICA(-eyes)AUDpreproc.mat, DS2=250Hz, FIR=2-30Hz, centnorm=1, step=1, win=2, TD, 1-90.mat' #0.61 #0.74(EEGnet.v2)\n",
    "\n",
    "# file = 'Merged456-197-289_ICA(-eyes)+AUDpreproc.mat, DS2=250Hz, FIR=2-30Hz, centnorm=1, step=2, win=2, TD, 1-93.mat' # 0.71 #0.85(EEGnet.v2)\n",
    "file = 'Merged456-197-289_ICA(-eyes)+AUDpreproc.mat, DS2=64Hz, FIR=2-30Hz, centnorm=1, step=2, win=2, TD, 1-93.mat' #0.80(EEGnet.v2)\n",
    "\n",
    "\n",
    "# file = 'Merged456-197-289_ICA(-eyes)+AUDpreproc.mat, DS2=64Hz, FIR=1-30Hz, centnorm=1, step=2, win=4, TD, 1-93.mat' #0.7\n",
    "# file = 'Merged456-197-289_ICA(-eyes)+AUDpreproc.mat, DS2=64Hz, FIR=1-30Hz, centnorm=1, step=2, win=2, TD, 1-93.mat'\n",
    "\n",
    "# file = 'Merged456-1-94_ICA(-2,3ICs)+AUDpreproc.mat, DS2=64Hz, FIR=2-30Hz, centnorm=1, step=2, win=2, TD, 1-95.mat' #0.61\n",
    "# file = 'EEG_ICA(-123_ICs)+proc_AUD_101_192_Merged456.mat, DS2=64Hz, FIR=2-30Hz, centnorm=1, step=2, win=2, TD, 1-92.mat'\n",
    "\n",
    "SHUFFLE = False\n",
    "BATCH_SIZE = 20\n",
    "TEST_TRAIN = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (450, 128, 60)\n",
      "Original labels shape: (450, 1)\n",
      "Original data type: float32\n",
      "Normalized data type: float16\n",
      "test input shape (113, 128, 60) Nomralized MEAN: -2.754e-05 min -4.816 max 5.66\n",
      "train input shape (337, 128, 60) Nomralized MEAN: -1.25e-05 min -16.14 max 19.11\n",
      "test labels shape (113, 2) Nomralized MEAN: 0.5 min 0.0 max 1.0\n",
      "train labels shape (337, 2) Nomralized MEAN: 0.5 min 0.0 max 1.0\n"
     ]
    }
   ],
   "source": [
    "# get the Dataset:\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "def load_data(file, SHUFFLE, BATCH_SIZE, TEST_TRAIN):\n",
    "        \n",
    "    \n",
    "\n",
    "    path = '/home/amplifier/home/DATASETS/' + file\n",
    "    mat_contents = sio.loadmat(path)\n",
    "    X = mat_contents['X']\n",
    "    Y = mat_contents['Z']\n",
    "\n",
    "    if X.shape[1]<X.shape[2]:\n",
    "        X = np.transpose(X,[0,2,1])\n",
    "\n",
    "    if Y.shape[1] > Y.shape[0]:\n",
    "        Y = Y.T\n",
    "\n",
    "    print('Original data shape:', X.shape)\n",
    "    print('Original labels shape:', Y.shape)\n",
    "\n",
    "    # verify that the model REALLY finds a mapping between the input and the labels. If we get\n",
    "    # our accuracy by chance, then we should get the same accuracy on a permuted dataset:\n",
    "    # Y = np.random.permutation(Y)\n",
    "\n",
    "\n",
    "    # winsize = mat_contents['winsize']\n",
    "    # stepsize = mat_contents['stepsize']\n",
    "    # trial_len = mat_contents['trial_len']\n",
    "    # low_cutoff = mat_contents['low_cutoff']\n",
    "    # high_cutoff = mat_contents['high_cutoff']\n",
    "    # source = mat_contents['filein']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_TRAIN, shuffle=SHUFFLE)\n",
    "    print('Original data type:', x_train.dtype)\n",
    "\n",
    "    # convert to float64 for numerical stability:\n",
    "    x_train = x_train.astype('float64')\n",
    "    y_train = y_train.astype('float64')\n",
    "    x_test = x_test.astype('float64')\n",
    "    y_test = y_test.astype('float64')\n",
    "\n",
    "    # one hot encode the labels:\n",
    "    onehot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "    y_train = onehot_encoder.fit_transform(y_train)\n",
    "    y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "    # convert to float16 to save space:\n",
    "    x_train = x_train.astype('float16')\n",
    "    y_train = y_train.astype('float16')\n",
    "    x_test = x_test.astype('float16')\n",
    "    y_test = y_test.astype('float16')\n",
    "    print('Normalized data type:', x_train.dtype)\n",
    "\n",
    "    leng = X.shape[1] # if you work in the FD, this is the height of the sample time-frequency image, othewise EEG channels\n",
    "    chan = X.shape[2] # if you work in the FD, this is the width of the sample time-frequency image, othewise time samples of EEG signal\n",
    "\n",
    "    if len(X.shape)==3:\n",
    "        streams = 1 # this is EEG channels if you work with frequency domain, in the TD streams = 1\n",
    "    if len(X.shape)==4:\n",
    "        streams = X.shape[3] # this is EEG channels if you work with frequency domain, in the TD streams = 1\n",
    "\n",
    "\n",
    "    print('test input shape', x_test.shape, \"Nomralized MEAN:\", np.mean(x_test), \"min\", np.min(x_test),\"max\", np.max(x_test))\n",
    "    print('train input shape', x_train.shape, \"Nomralized MEAN:\", np.mean(x_train), \"min\", np.min(x_train),\"max\", np.max(x_train))\n",
    "\n",
    "    print('test labels shape', y_test.shape, \"Nomralized MEAN:\", np.mean(y_test), \"min\", np.min(y_test),\"max\", np.max(y_test))\n",
    "    print('train labels shape', y_train.shape, \"Nomralized MEAN:\", np.mean(y_train), \"min\", np.min(y_train),\"max\", np.max(y_train))\n",
    "\n",
    "    # print('Window length', winsize)\n",
    "    # print('Step size:', stepsize)\n",
    "    # print('Trial length:', trial_len)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = load_data(file, SHUFFLE, BATCH_SIZE, TEST_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rightsize(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0],1,x_train.shape[1],x_train.shape[2])\n",
    "    x_train = x_train.transpose(0,1,3,2)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,x_test.shape[1],x_test.shape[2])\n",
    "    x_test = x_test.transpose(0,1,3,2)\n",
    "    print(x_train.shape,'\\n',\n",
    "          x_test.shape,'\\n',\n",
    "          y_train.shape,'\\n',\n",
    "          y_test.shape)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 1, 60, 128) \n",
      " (113, 1, 60, 128) \n",
      " (337, 2) \n",
      " (113, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,4,60,128], [1,4,1,1], [1,4,1,1], [1,4,1,1], [1,4,1,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,4,60,128], [1,4,1,1], [1,4,1,1], [1,4,1,1], [1,4,1,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc70128ce9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mChans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 kernLength = 125)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home/NEW_DL/EEGModels.py\u001b[0m in \u001b[0;36mEEGNet\u001b[0;34m(nb_classes, Chans, Samples, dropoutRate, kernLength, F1, D, F2, dropoutType)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                    \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                    use_bias = False, data_format='channels_first')(input1)\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mblock1\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n\u001b[1;32m    134\u001b[0m                                    \u001b[0mdepth_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    202\u001b[0m         return K.in_train_phase(normed_training,\n\u001b[1;32m    203\u001b[0m                                 \u001b[0mnormalize_inference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                                 training=training)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36min_train_phase\u001b[0;34m(x, alt, training)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m     \u001b[0;31m# else: assume learning phase is a placeholder tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3069\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3070\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muses_learning_phase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3071\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mswitch\u001b[0;34m(condition, then_expression, else_expression)\u001b[0m\n\u001b[1;32m   3002\u001b[0m         x = tf.cond(condition,\n\u001b[1;32m   3003\u001b[0m                     \u001b[0mthen_expression_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3004\u001b[0;31m                     else_expression_fn)\n\u001b[0m\u001b[1;32m   3005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m         \u001b[0;31m# tf.where needs its condition tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 instructions)\n\u001b[0;32m--> 432\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    434\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   2070\u001b[0m     \u001b[0mcontext_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m     \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m     \u001b[0morig_res_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_res_f\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"false_fn must have a return value.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[0;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m     \u001b[0moriginal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_summaries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_summaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mnormalize_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mbroadcast_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     epsilon=self.epsilon)\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 return K.batch_normalization(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(x, mean, var, beta, gamma, axis, epsilon)\u001b[0m\n\u001b[1;32m   1892\u001b[0m                 \u001b[0mvariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_data_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m                 \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1895\u001b[0m             )\n\u001b[1;32m   1896\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m    902\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    905\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   3427\u001b[0m         \u001b[0;34m\"FusedBatchNorm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m         \u001b[0mvariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m         is_training=is_training, name=name)\n\u001b[0m\u001b[1;32m   3430\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,4,60,128], [1,4,1,1], [1,4,1,1], [1,4,1,1], [1,4,1,1]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.models import load_model\n",
    "\n",
    "from EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
    "\n",
    "x_train, x_test, y_train, y_test = rightsize(x_train, x_test, y_train, y_test)\n",
    "\n",
    "model  = EEGNet(nb_classes = 2,\n",
    "                Chans = x_train.shape[2],\n",
    "                Samples = x_train.shape[3],\n",
    "                kernLength = 125)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 337 samples, validate on 113 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 0.6984 - acc: 0.4688 - val_loss: 0.6920 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50442, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 2/300\n",
      " - 0s - loss: 0.6880 - acc: 0.5668 - val_loss: 0.6908 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50442 to 0.52212, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 3/300\n",
      " - 0s - loss: 0.6913 - acc: 0.5163 - val_loss: 0.6901 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.52212 to 0.53097, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 4/300\n",
      " - 0s - loss: 0.6888 - acc: 0.5490 - val_loss: 0.6898 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/300\n",
      " - 0s - loss: 0.6851 - acc: 0.5786 - val_loss: 0.6882 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.53097 to 0.53982, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 6/300\n",
      " - 0s - loss: 0.6844 - acc: 0.6053 - val_loss: 0.6896 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/300\n",
      " - 0s - loss: 0.6872 - acc: 0.5312 - val_loss: 0.6880 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.53982 to 0.57522, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 8/300\n",
      " - 0s - loss: 0.6768 - acc: 0.5994 - val_loss: 0.6878 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.57522 to 0.58407, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 9/300\n",
      " - 0s - loss: 0.6743 - acc: 0.6053 - val_loss: 0.6888 - val_acc: 0.5575\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/300\n",
      " - 0s - loss: 0.6753 - acc: 0.5964 - val_loss: 0.6879 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/300\n",
      " - 0s - loss: 0.6697 - acc: 0.6142 - val_loss: 0.6880 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.58407 to 0.58407, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 12/300\n",
      " - 0s - loss: 0.6700 - acc: 0.6291 - val_loss: 0.6874 - val_acc: 0.5575\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/300\n",
      " - 0s - loss: 0.6666 - acc: 0.6024 - val_loss: 0.6894 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.58407 to 0.58407, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 14/300\n",
      " - 0s - loss: 0.6604 - acc: 0.6350 - val_loss: 0.6924 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/300\n",
      " - 0s - loss: 0.6624 - acc: 0.6231 - val_loss: 0.6940 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/300\n",
      " - 0s - loss: 0.6662 - acc: 0.6320 - val_loss: 0.6935 - val_acc: 0.5487\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/300\n",
      " - 0s - loss: 0.6532 - acc: 0.6053 - val_loss: 0.6921 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/300\n",
      " - 0s - loss: 0.6586 - acc: 0.5905 - val_loss: 0.6944 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/300\n",
      " - 0s - loss: 0.6412 - acc: 0.6766 - val_loss: 0.6933 - val_acc: 0.5664\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/300\n",
      " - 0s - loss: 0.6395 - acc: 0.6647 - val_loss: 0.6901 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/300\n",
      " - 0s - loss: 0.6341 - acc: 0.6499 - val_loss: 0.6868 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.58407 to 0.59292, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 22/300\n",
      " - 0s - loss: 0.6309 - acc: 0.6647 - val_loss: 0.6854 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/300\n",
      " - 0s - loss: 0.6370 - acc: 0.6855 - val_loss: 0.6818 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.59292 to 0.61062, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 24/300\n",
      " - 0s - loss: 0.6219 - acc: 0.6825 - val_loss: 0.6752 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/300\n",
      " - 0s - loss: 0.6089 - acc: 0.6795 - val_loss: 0.6711 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.61062 to 0.61947, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 26/300\n",
      " - 0s - loss: 0.6237 - acc: 0.6706 - val_loss: 0.6707 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/300\n",
      " - 0s - loss: 0.6050 - acc: 0.6914 - val_loss: 0.6543 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.61947 to 0.64602, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 28/300\n",
      " - 0s - loss: 0.5991 - acc: 0.6855 - val_loss: 0.6839 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/300\n",
      " - 0s - loss: 0.5988 - acc: 0.7033 - val_loss: 0.6311 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/300\n",
      " - 0s - loss: 0.5768 - acc: 0.7092 - val_loss: 0.6342 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/300\n",
      " - 0s - loss: 0.5627 - acc: 0.7300 - val_loss: 0.6286 - val_acc: 0.6549\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.64602 to 0.65487, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 32/300\n",
      " - 0s - loss: 0.5678 - acc: 0.7478 - val_loss: 0.6216 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.65487 to 0.67257, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 33/300\n",
      " - 0s - loss: 0.5391 - acc: 0.7656 - val_loss: 0.6456 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.67257 to 0.67257, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 34/300\n",
      " - 0s - loss: 0.5344 - acc: 0.7567 - val_loss: 0.6061 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.67257 to 0.72566, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 35/300\n",
      " - 0s - loss: 0.5566 - acc: 0.7389 - val_loss: 0.5566 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.72566 to 0.72566, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 36/300\n",
      " - 0s - loss: 0.5229 - acc: 0.7864 - val_loss: 0.5290 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.72566 to 0.73451, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 37/300\n",
      " - 0s - loss: 0.5171 - acc: 0.7834 - val_loss: 0.5278 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.73451 to 0.75221, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 38/300\n",
      " - 0s - loss: 0.5010 - acc: 0.7596 - val_loss: 0.5555 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/300\n",
      " - 0s - loss: 0.5190 - acc: 0.7774 - val_loss: 0.5207 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.75221 to 0.76106, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 40/300\n",
      " - 0s - loss: 0.4880 - acc: 0.7685 - val_loss: 0.5378 - val_acc: 0.7434\n",
      "\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/300\n",
      " - 0s - loss: 0.4759 - acc: 0.7834 - val_loss: 0.5079 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/300\n",
      " - 0s - loss: 0.4685 - acc: 0.7953 - val_loss: 0.5482 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/300\n",
      " - 0s - loss: 0.4789 - acc: 0.7774 - val_loss: 0.5640 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/300\n",
      " - 0s - loss: 0.4651 - acc: 0.8012 - val_loss: 0.5330 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/300\n",
      " - 0s - loss: 0.4510 - acc: 0.8012 - val_loss: 0.5622 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/300\n",
      " - 0s - loss: 0.4301 - acc: 0.8160 - val_loss: 0.5546 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/300\n",
      " - 0s - loss: 0.4442 - acc: 0.8309 - val_loss: 0.5361 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.76106 to 0.79646, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 48/300\n",
      " - 0s - loss: 0.4561 - acc: 0.8042 - val_loss: 0.5280 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/300\n",
      " - 0s - loss: 0.4202 - acc: 0.8042 - val_loss: 0.5439 - val_acc: 0.7434\n",
      "\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/300\n",
      " - 0s - loss: 0.4427 - acc: 0.7774 - val_loss: 0.5428 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00050: val_acc did not improve\n",
      "Epoch 51/300\n",
      " - 0s - loss: 0.4319 - acc: 0.8012 - val_loss: 0.5433 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00051: val_acc did not improve\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4313 - acc: 0.8338 - val_loss: 0.5468 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00052: val_acc did not improve\n",
      "Epoch 53/300\n",
      " - 0s - loss: 0.4186 - acc: 0.8101 - val_loss: 0.6586 - val_acc: 0.6726\n",
      "\n",
      "Epoch 00053: val_acc did not improve\n",
      "Epoch 54/300\n",
      " - 0s - loss: 0.4282 - acc: 0.8131 - val_loss: 0.5510 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00054: val_acc did not improve\n",
      "Epoch 55/300\n",
      " - 0s - loss: 0.4027 - acc: 0.8309 - val_loss: 0.5656 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00055: val_acc did not improve\n",
      "Epoch 56/300\n",
      " - 0s - loss: 0.3767 - acc: 0.8368 - val_loss: 0.5368 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00056: val_acc did not improve\n",
      "Epoch 57/300\n",
      " - 0s - loss: 0.3921 - acc: 0.8249 - val_loss: 0.5852 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00057: val_acc did not improve\n",
      "Epoch 58/300\n",
      " - 0s - loss: 0.3831 - acc: 0.8338 - val_loss: 0.5575 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00058: val_acc did not improve\n",
      "Epoch 59/300\n",
      " - 0s - loss: 0.3663 - acc: 0.8576 - val_loss: 0.5715 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00059: val_acc did not improve\n",
      "Epoch 60/300\n",
      " - 0s - loss: 0.3592 - acc: 0.8576 - val_loss: 0.5705 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00060: val_acc did not improve\n",
      "Epoch 61/300\n",
      " - 0s - loss: 0.3092 - acc: 0.8932 - val_loss: 0.5691 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00061: val_acc did not improve\n",
      "Epoch 62/300\n",
      " - 0s - loss: 0.3412 - acc: 0.8457 - val_loss: 0.5417 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00062: val_acc did not improve\n",
      "Epoch 63/300\n",
      " - 0s - loss: 0.3445 - acc: 0.8665 - val_loss: 0.5622 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00063: val_acc did not improve\n",
      "Epoch 64/300\n",
      " - 0s - loss: 0.3532 - acc: 0.8665 - val_loss: 0.5564 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00064: val_acc did not improve\n",
      "Epoch 65/300\n",
      " - 0s - loss: 0.3511 - acc: 0.8516 - val_loss: 0.6464 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00065: val_acc did not improve\n",
      "Epoch 66/300\n",
      " - 0s - loss: 0.3425 - acc: 0.8398 - val_loss: 0.5916 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00066: val_acc did not improve\n",
      "Epoch 67/300\n",
      " - 0s - loss: 0.3555 - acc: 0.8398 - val_loss: 0.6579 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00067: val_acc did not improve\n",
      "Epoch 68/300\n",
      " - 0s - loss: 0.3440 - acc: 0.8546 - val_loss: 0.5735 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00068: val_acc did not improve\n",
      "Epoch 69/300\n",
      " - 0s - loss: 0.3287 - acc: 0.8724 - val_loss: 0.6319 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00069: val_acc did not improve\n",
      "Epoch 70/300\n",
      " - 0s - loss: 0.3237 - acc: 0.8635 - val_loss: 0.6059 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00070: val_acc did not improve\n",
      "Epoch 71/300\n",
      " - 0s - loss: 0.2936 - acc: 0.8991 - val_loss: 0.6326 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00071: val_acc did not improve\n",
      "Epoch 72/300\n",
      " - 0s - loss: 0.3427 - acc: 0.8457 - val_loss: 0.5705 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00072: val_acc did not improve\n",
      "Epoch 73/300\n",
      " - 0s - loss: 0.3233 - acc: 0.8694 - val_loss: 0.5729 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00073: val_acc did not improve\n",
      "Epoch 74/300\n",
      " - 0s - loss: 0.3187 - acc: 0.8754 - val_loss: 0.6191 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00074: val_acc did not improve\n",
      "Epoch 75/300\n",
      " - 0s - loss: 0.3048 - acc: 0.8843 - val_loss: 0.5963 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00075: val_acc did not improve\n",
      "Epoch 76/300\n",
      " - 0s - loss: 0.3055 - acc: 0.8724 - val_loss: 0.5959 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00076: val_acc did not improve\n",
      "Epoch 77/300\n",
      " - 0s - loss: 0.3377 - acc: 0.8576 - val_loss: 0.6167 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00077: val_acc did not improve\n",
      "Epoch 78/300\n",
      " - 0s - loss: 0.3075 - acc: 0.8813 - val_loss: 0.6185 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00078: val_acc did not improve\n",
      "Epoch 79/300\n",
      " - 0s - loss: 0.2957 - acc: 0.8843 - val_loss: 0.6014 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00079: val_acc did not improve\n",
      "Epoch 80/300\n",
      " - 0s - loss: 0.3178 - acc: 0.8635 - val_loss: 0.6128 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00080: val_acc did not improve\n",
      "Epoch 81/300\n",
      " - 0s - loss: 0.2910 - acc: 0.8843 - val_loss: 0.6197 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00081: val_acc did not improve\n",
      "Epoch 82/300\n",
      " - 0s - loss: 0.3089 - acc: 0.8754 - val_loss: 0.5942 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.79646 to 0.79646, saving model to /home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5\n",
      "Epoch 83/300\n",
      " - 0s - loss: 0.2725 - acc: 0.8932 - val_loss: 0.5783 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00083: val_acc did not improve\n",
      "Epoch 84/300\n",
      " - 0s - loss: 0.2899 - acc: 0.8932 - val_loss: 0.5972 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00084: val_acc did not improve\n",
      "Epoch 85/300\n",
      " - 0s - loss: 0.2866 - acc: 0.8991 - val_loss: 0.6505 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00085: val_acc did not improve\n",
      "Epoch 86/300\n",
      " - 0s - loss: 0.2595 - acc: 0.9080 - val_loss: 0.6151 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00086: val_acc did not improve\n",
      "Epoch 87/300\n",
      " - 0s - loss: 0.2900 - acc: 0.8872 - val_loss: 0.6481 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00087: val_acc did not improve\n",
      "Epoch 88/300\n",
      " - 0s - loss: 0.2759 - acc: 0.8813 - val_loss: 0.5949 - val_acc: 0.7434\n",
      "\n",
      "Epoch 00088: val_acc did not improve\n",
      "Epoch 89/300\n",
      " - 0s - loss: 0.2755 - acc: 0.8932 - val_loss: 0.6147 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00089: val_acc did not improve\n",
      "Epoch 90/300\n",
      " - 0s - loss: 0.2828 - acc: 0.9021 - val_loss: 0.5952 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00090: val_acc did not improve\n",
      "Epoch 91/300\n",
      " - 0s - loss: 0.2920 - acc: 0.8783 - val_loss: 0.6026 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00091: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, mode='min')\n",
    "checkpointer = ModelCheckpoint(filepath='/home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5',\n",
    "                               verbose=1,\n",
    "                               monitor='val_acc',\n",
    "                               save_best_only=True)\n",
    "\n",
    "TB = TensorBoard(log_dir='/home/amplifier/home/CNN_stim')\n",
    "\n",
    "train_history = model.fit(x_train, y_train,\n",
    "                epochs=300,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=[TB, checkpointer, early_stopping])\n",
    "\n",
    "model.save('/home/amplifier/home/NEW_DL/models/EEGnet_NEWEST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02099c1d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# print(np.array(history.losses))\n",
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.title('AdaDelta')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_accuracy(decoded_test, decoded_train):\n",
    "    # now test sample by sample\n",
    "    cor_test = []\n",
    "    L = x_test.shape\n",
    "    for sample_no in range(x_test.shape[0]):\n",
    "        pred = decoded_test[sample_no,:] #model.predict(np.expand_dims(x_test[sample_no],0))\n",
    "        if ((pred[0]<pred[1]) and (y_test[sample_no,0] < y_test[sample_no,1]) or\n",
    "           ((pred[0]>pred[1]) and (y_test[sample_no,0] > y_test[sample_no,1]))):\n",
    "            cor_test.append(1)\n",
    "        else:\n",
    "            cor_test.append(0)\n",
    "\n",
    "    cor_train = []\n",
    "    L = x_train.shape\n",
    "    for sample_no in range(x_train.shape[0]):\n",
    "        pred = decoded_train[sample_no,:] #pred = model.predict(np.expand_dims(x_train[sample_no],0))\n",
    "        if ((pred[0]<pred[1]) and (y_train[sample_no,0] < y_train[sample_no,1]) or\n",
    "           ((pred[0]>pred[1]) and (y_train[sample_no,0] > y_train[sample_no,1]))):\n",
    "            cor_train.append(1)\n",
    "        else:\n",
    "            cor_train.append(0)\n",
    "\n",
    "    # Report accuracies\n",
    "    print('Accuracy on the test data:', np.mean(cor_test))\n",
    "    print('Accuracy on the training data:', np.mean(cor_train))\n",
    "    return cor_test, cor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy at the end of the training:\n",
      "Accuracy on the test data: 0.796460176991\n",
      "Accuracy on the training data: 0.949554896142\n",
      "Best saved model accuracy:\n",
      "Accuracy on the test data: 0.796460176991\n",
      "Accuracy on the training data: 0.949554896142\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy at the end of the training:')\n",
    "decoded_test = model.predict(x_test)\n",
    "decoded_train = model.predict(x_train)\n",
    "cor_test, cor_train = report_accuracy(decoded_test, decoded_train)\n",
    "\n",
    "\n",
    "print('Best saved model accuracy:')\n",
    "model.load_weights('/home/amplifier/home/NEW_DL/weights/EEGnet_NEWEST_wts.h5')\n",
    "decoded_test = model.predict(x_test)\n",
    "decoded_train = model.predict(x_train)\n",
    "cor_test, cor_train = report_accuracy(decoded_test, decoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cor_test as csv for future analysis:\n",
    "import csv\n",
    "with open('img_test.csv', 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ = pd.DataFrame(columns=['algorithm',\n",
    "#                            'SHUFFLE',\n",
    "#                            'BATCH_SIZE',\n",
    "#                            'TEST_TRAIN',\n",
    "#                            'DS_FREQ',\n",
    "#                            'n_bins',\n",
    "#                            'RESIZE',\n",
    "#                            'width',\n",
    "#                            'height',\n",
    "#                            'SENSITIVITY',\n",
    "#                            'dataset',\n",
    "#                            'val_acc',\n",
    "#                            'acc'])\n",
    "\n",
    "# df_.loc[0] = ['1D',\n",
    "#               SHUFFLE,\n",
    "#               BATCH_SIZE,\n",
    "#               TEST_TRAIN,\n",
    "#               DS_FREQ,\n",
    "#               n_bins,\n",
    "#               RESIZE,\n",
    "#               width,\n",
    "#               height,\n",
    "#               SENSITIVITY,\n",
    "#               file,\n",
    "#               np.mean(cor_test),\n",
    "#               np.mean(cor_train)]\n",
    "# # df.to_csv('/home/amplifier/home/NEW_DL/weights/blank_document.csv', index=False)\n",
    "# df = pd.read_csv('/home/amplifier/home/NEW_DL/weights/performances.csv')\n",
    "# df = df.append(df_, ignore_index=True)\n",
    "# df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "# df.to_csv('/home/amplifier/home/NEW_DL/weights/performances.csv', index=False)\n",
    "# df = pd.read_csv('/home/amplifier/home/NEW_DL/weights/performances.csv')\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log performance to file:\n",
    "# import csv   \n",
    "# fields=['1D', 'MY04', np.mean(cor_test), np.mean(cor_train)]\n",
    "# with open(r'/home/amplifier/home/NEW_DL/weights/document.csv', 'a') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "GT = []\n",
    "\n",
    "for i in range(len(decoded_test)):\n",
    "    if decoded_test[i][0]<decoded_test[i][1]:\n",
    "        W.append('right')\n",
    "    if decoded_test[i][0]>decoded_test[i][1]:\n",
    "        W.append('left')\n",
    "\n",
    "    if y_test[i][0]<y_test[i][1]:\n",
    "        GT.append('right')\n",
    "    if y_test[i][0]>y_test[i][1]:\n",
    "        GT.append('left')\n",
    "        \n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['left', 'right'] # 1 for right, 0 for left\n",
    "cm = confusion_matrix(GT, W, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.matshow(cm)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1: \n",
      "\n",
      "Accuracy on the test data: 0.796460176991\n",
      "Accuracy on the training data: 0.988130563798\n",
      "\n",
      "===========================\n",
      "\n",
      "model 2: \n",
      "\n",
      "Accuracy on the test data: 0.769911504425\n",
      "Accuracy on the training data: 1.0\n",
      "\n",
      "===========================\n",
      "\n",
      "model 3: \n",
      "\n",
      "Accuracy on the test data: 0.769911504425\n",
      "Accuracy on the training data: 0.910979228487\n",
      "\n",
      "===========================\n",
      "\n",
      "mean of model 1&2 (of softmax layers): \n",
      "\n",
      "Trilogic:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('model 1: \\n')\n",
    "decoded_test = m1_decoded_test # 0.7522\n",
    "decoded_train = m1_decoded_train # 0.9050\n",
    "\n",
    "res = np.zeros([decoded_test.shape[0], 3])\n",
    "\n",
    "cor_test, cor_train = report_accuracy(decoded_test, decoded_train)\n",
    "res[:,0] = cor_test\n",
    "print('\\n===========================\\n')\n",
    "\n",
    "print('model 2: \\n')\n",
    "decoded_test = m2_decoded_test # 0.7699\n",
    "decoded_train = m2_decoded_train # 1.0\n",
    "cor_test, cor_train = report_accuracy(decoded_test, decoded_train)\n",
    "res[:,1] = cor_test\n",
    "print('\\n===========================\\n')\n",
    "\n",
    "print('model 3: \\n')\n",
    "decoded_test = m3_decoded_test # 0.7699\n",
    "decoded_train = m3_decoded_train # 1.0\n",
    "cor_test, cor_train = report_accuracy(decoded_test, decoded_train)\n",
    "res[:,2] = cor_test\n",
    "print('\\n===========================\\n')\n",
    "\n",
    "\n",
    "print('mean of model 1&2 (of softmax layers): \\n')\n",
    "_decoded_test = np.dstack((m1_decoded_test,m2_decoded_test)) # 0.7876\n",
    "decoded_test = np.mean(_decoded_test,axis=2)\n",
    "_decoded_train = np.dstack((m1_decoded_train,m2_decoded_train)) # 1.0\n",
    "decoded_train = np.mean(_decoded_train,axis=2)\n",
    "\n",
    "print('Trilogic:')\n",
    "np.mean(np.round(np.mean(res, axis=1)))\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
