{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# make sure you don't hog all the video memory\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "###################################\n",
    "\n",
    "from keras.layers import Input, Lambda, merge, Dense, DepthwiseConv2D, Activation, AveragePooling2D\n",
    "from keras.layers import Flatten,Conv2D, MaxPooling2D, Dropout, BatchNormalization, SeparableConv2D\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (450, 60, 128)\n",
      "Original labels shape: (450, 1)\n"
     ]
    }
   ],
   "source": [
    "SHUFFLE = False\n",
    "Seed = 4\n",
    "SCRAMBLE_FOR_TEST = False\n",
    "AUGMENT = True\n",
    "\n",
    "file = 'Merged456-197-289_ICA(-eyes)+AUDpreproc.mat, DS2=64Hz, FIR=2-30Hz, centnorm=1, step=2, win=2, TD, 1-93.mat' #0.75(vanilla EEGnet), 0. (SiameseL1)\n",
    "# file = 'Merged456-1-94_ICA(-2,3ICs)+AUDpreproc.mat, DS2=64Hz, FIR=2-30Hz, centnorm=1, step=2, win=2, TD, 1-95.mat' #0.61(vanilla EEGnet)\n",
    "# get the Dataset:\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "path = '/home/amplifier/home/DATASETS/' + file\n",
    "mat_contents = sio.loadmat(path)\n",
    "X = mat_contents['X']\n",
    "Y = mat_contents['Z']\n",
    "\n",
    "if X.shape[1]<X.shape[2]:\n",
    "    X = np.transpose(X,[0,2,1])\n",
    "\n",
    "if Y.shape[1] > Y.shape[0]:\n",
    "    Y = Y.T\n",
    "\n",
    "    \n",
    "# # one hot encode the labels:\n",
    "# onehot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "# Y = onehot_encoder.fit_transform(Y)\n",
    "\n",
    "X = X.transpose(0,2,1)\n",
    "\n",
    "print('Original data shape:', X.shape)\n",
    "print('Original labels shape:', Y.shape)\n",
    "\n",
    "\n",
    "# verify that the model REALLY finds a mapping between the input and the labels. If we get\n",
    "# our accuracy by chance, then we should get the same accuracy on a permuted dataset:\n",
    "if SCRAMBLE_FOR_TEST==True:\n",
    "    Y = np.random.permutation(Y)\n",
    "Y = Y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sys import getsizeof\n",
    "\n",
    "    \n",
    "def get_pairs(X,Y):\n",
    "    print('X', X.shape)\n",
    "    print('Y', Y.shape)\n",
    "    \n",
    "    # get the full permutation (very LARGE DATASET!)\n",
    "\n",
    "    temp = []\n",
    "    for x in product(range(Y.shape[0]), repeat=2):\n",
    "        temp.append(np.array(x))\n",
    "    \n",
    "    n_perm = len(temp)\n",
    "    temp = np.array(temp)\n",
    "    print('temp', temp.shape)\n",
    "\n",
    "    XX = np.zeros([n_perm,2,60,128])\n",
    "    XX[:,0,:,:] = X[[temp[i,0] for i in range(n_perm)],:,:]\n",
    "    XX[:,1,:,:] = X[[temp[i,1] for i in range(n_perm)],:,:]\n",
    "\n",
    "    print('Data size in memory (GB):', np.round(getsizeof(XX)/1024/1024/1024, 2))\n",
    "\n",
    "    YY = np.zeros([n_perm, 2])\n",
    "    YY[:,0] = Y[[temp[i,0] for i in range(n_perm)]].flatten()\n",
    "    YY[:,1] = Y[[temp[i,1] for i in range(n_perm)]].flatten()\n",
    "\n",
    "    YYY = []\n",
    "    for i in range(len(YY)):\n",
    "        YYY.append(0 if YY[i,0]==YY[i,1] else 1)\n",
    "    YYY = np.array(YYY).flatten()\n",
    "    \n",
    "    # diag:\n",
    "#     print (XX.shape, YYY.shape)\n",
    "#     for i in range(XX.shape[0]):\n",
    "#         print(temp[i,0], YY[i,0], temp[i,1], YY[i,1], YYY[i])\n",
    "\n",
    "    print('Left Col', np.mean(YY[:,0]))\n",
    "    print('Right Col', np.mean(YY[:,1]))\n",
    "    print('Labels', np.mean(YYY), '\\n')\n",
    "    \n",
    "    print(\"\\nPairs\", XX.shape)\n",
    "    print(\"Labels\", YYY.shape)\n",
    "    \n",
    "    return XX, YYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 60, 128)\n",
      "(45, 60, 128)\n",
      "(405,)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, = train_test_split(X, Y, test_size=0.1, shuffle=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (45, 60, 128)\n",
      "Y (45,)\n",
      "temp (2025, 2)\n",
      "Data size in memory (GB): 0.23\n",
      "Left Col 0.4888888888888889\n",
      "Right Col 0.4888888888888889\n",
      "Labels 0.4997530864197531 \n",
      "\n",
      "\n",
      "Pairs (2025, 2, 60, 128)\n",
      "Labels (2025,)\n",
      "X (405, 60, 128)\n",
      "Y (405,)\n",
      "temp (164025, 2)\n",
      "Data size in memory (GB): 18.77\n",
      "Left Col 0.5012345679012346\n",
      "Right Col 0.5012345679012346\n",
      "Labels 0.4999969516841945 \n",
      "\n",
      "\n",
      "Pairs (164025, 2, 60, 128)\n",
      "Labels (164025,)\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = get_pairs(x_test, y_test)\n",
    "X_train, Y_train = get_pairs(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape)\n",
    "# val_set = np.random.choice(range(len(Y)), 50, replace=False)\n",
    "# print(val_set.shape)\n",
    "# X_val = X[val_set,:,:]\n",
    "# Y_val = Y[val_set]\n",
    "# print('Validation Set')\n",
    "# print('X_val:', X_val.shape)\n",
    "# print('Y_val:', Y_val.shape)\n",
    "\n",
    "# X = np.delete(X,val_set,0)\n",
    "# Y = np.delete(Y,val_set,0)\n",
    "# print('Train & Test')\n",
    "# print(X.shape)\n",
    "# print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SZ = 195\n",
    "# idx_a = []\n",
    "# idx_b = []\n",
    "# idy_a = []\n",
    "# idy_b = []\n",
    "# YYY = []\n",
    "# for i in range(2):\n",
    "#     addr = np.array(np.where(Y==i)).flatten()\n",
    "#     a = np.random.choice(addr, size=SZ, replace=False).tolist()\n",
    "#     b = np.random.choice(addr, size=SZ, replace=False).tolist()\n",
    "#     idx_a = idx_a + a\n",
    "#     idx_b = idx_b + b\n",
    "#     idy_a = idy_a + a\n",
    "#     idy_b = idy_b + b\n",
    "\n",
    "# for i in range(2):\n",
    "#     addr_a = np.array(np.where(Y==i)).flatten()\n",
    "#     addr_b = np.array(np.where(Y!=i)).flatten()\n",
    "#     a = np.random.choice(addr_a, size=SZ, replace=False).tolist()\n",
    "#     b = np.random.choice(addr_b, size=SZ, replace=False).tolist()\n",
    "#     idx_a = idx_a + a\n",
    "#     idx_b = idx_b + b\n",
    "#     idy_a = idy_a + a\n",
    "#     idy_b = idy_b + b\n",
    "    \n",
    "# XX = [X[idx_a], X[idx_b]]\n",
    "# YY = [Y[idy_a], Y[idy_b]]\n",
    "\n",
    "# for i in range(len(idx_a)):\n",
    "#     YYY.append(0 if YY[0][i]==YY[1][i] else 1)\n",
    "# YYY = np.array(YYY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(idy_a)):\n",
    "#     print(i, idy_a[i], idy_b[i], YY[0][i], YY[1][i], YYY[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.arange(len(idx_a))\n",
    "# train_test = 0.8\n",
    "\n",
    "# # sample ordinal numbers of \n",
    "# train_id = np.random.choice(rng ,np.round(len(rng)*train_test).astype('int64'), replace=False)\n",
    "# test_id = rng[np.isin(rng,train_id, invert=True)]\n",
    "\n",
    "# x_train = [X[np.array(idx_a)[train_id]], X[np.array(idx_b)[train_id]]]\n",
    "# x_test = [X[np.array(idx_a)[test_id]], X[np.array(idx_b)[test_id]]]\n",
    "# y_train = YYY[train_id]\n",
    "# y_test = YYY[test_id]\n",
    "\n",
    "# print(len(idx_a))\n",
    "# print(len(y_train))\n",
    "# print(len(y_test))\n",
    "\n",
    "# print(np.mean(y_train))\n",
    "# print(np.mean(y_test))\n",
    "\n",
    "# x_train = np.array(x_train).transpose(1,0,2,3)\n",
    "# x_test = np.array(x_test).transpose(1,0,2,3)\n",
    "# y_train = np.array(y_train).flatten()\n",
    "# y_test = np.array(y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the full permutation (very LARGE DATASET!)\n",
    "# from itertools import product\n",
    "# from sys import getsizeof\n",
    "\n",
    "# temp = []\n",
    "# for x in product(range(Y.shape[0]), repeat=2):\n",
    "#     temp.append(np.array(x))\n",
    "\n",
    "# XX = np.zeros([len(temp), 2, 60, 128])\n",
    "# XX[:,0,:,:] = X[[temp[i][0] for i in range(len(temp))],:,:]\n",
    "# XX[:,1,:,:] = X[[temp[i][1] for i in range(len(temp))],:,:]\n",
    "\n",
    "\n",
    "# print('Data size in memory (GB):', np.round(getsizeof(XX)/1024/1024/1024, 2))\n",
    "\n",
    "# YY = np.zeros([len(temp), 2])\n",
    "# YY[:,0] = Y[[temp[i][0] for i in range(len(temp))]].flatten()\n",
    "# YY[:,1] = Y[[temp[i][1] for i in range(len(temp))]].flatten()\n",
    "\n",
    "# YYY = []\n",
    "# for i in range(len(YY)):\n",
    "#     YYY.append(1 if YY[i,0]==YY[i,1] else 0)\n",
    "# YYY = np.array(YYY).flatten()\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(XX,YYY, test_size=0.1, shuffle=True, random_state=10)\n",
    "# print (x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet_my(input1, nb_classes, Chans = 64, Samples = 128, \n",
    "             dropoutRate = 0.25, kernLength = 64, F1 = 4, \n",
    "             D = 2, F2 = 8, dropoutType = 'Dropout'):\n",
    "    \n",
    "    \"\"\" Keras Implementation of EEGNet (https://arxiv.org/abs/1611.08024)\n",
    "\n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.     \n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 4, F2 = F1 * D. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    init = RandomUniform(minval=-0.1, maxval=0.1, seed=29)\n",
    "    net = Sequential()\n",
    "    net.add (Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples,1),\n",
    "                                   use_bias = False, bias_initializer=init, kernel_initializer=init))\n",
    "    net.add (BatchNormalization())\n",
    "    net.add (DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.), bias_initializer=init, kernel_initializer=init))\n",
    "    net.add (BatchNormalization())\n",
    "    net.add (Activation('elu'))\n",
    "    net.add (AveragePooling2D((1, 4)))\n",
    "    net.add (dropoutType(dropoutRate))\n",
    "    net.add (SeparableConv2D(F2, (1, 16), use_bias = False, padding = 'same', bias_initializer=init, kernel_initializer=init))\n",
    "    net.add (BatchNormalization())\n",
    "    net.add (Activation('elu'))\n",
    "    net.add (AveragePooling2D((1, 8)))\n",
    "    net.add (dropoutType(dropoutRate))\n",
    "    net.add (Flatten())\n",
    "    net.add (Dense(nb_classes, kernel_constraint = max_norm(0.25), bias_initializer=init, kernel_initializer=init))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 60, 128, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 60, 128, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 10)           1338        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 10)           1338        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            11          lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,687\n",
      "Trainable params: 2,607\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n",
      "1.067009 1.067009\n"
     ]
    }
   ],
   "source": [
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "# def triplet_loss(y_true, y_pred):\n",
    "#     norm1 = K.sqrt(K.sum(K.square(y_pred[0] - y_pred[1]), axis=-1, keepdims=True))\n",
    "#     norm2 = K.sqrt(K.sum(K.square(y_pred[0] - y_pred[2]), axis=-1, keepdims=True))\n",
    "#     loss = norm1 - norm2 + 0.2\n",
    "#     return loss\n",
    "\n",
    "input_shape = X_train[-1,-1,:,:].shape + (1,)\n",
    "a_input = Input(input_shape)\n",
    "r_input = Input(input_shape)\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "# encoded NOT as Sequential (stack of layers), but as a Tensor!!!! if you add an argument, a Tensor is returned\n",
    "encoded_a = EEGNet_my(input_shape, 10, Chans=input_shape[0])(a_input)\n",
    "encoded_r = EEGNet_my(input_shape, 10, Chans=input_shape[0])(r_input)\n",
    "\n",
    "L1_distance = Lambda(lambda tensors: (K.abs(tensors[0] - tensors[1])))([encoded_a, encoded_r])\n",
    "L1_distance = Dense(1,activation='sigmoid', use_bias=True)(L1_distance)\n",
    "\n",
    "# siamese_net = Model(inputs=[a_input, r_input], outputs=[encoded_a, encoded_r, L1_distance])\n",
    "siamese_net = Model(inputs=[a_input, r_input], outputs=[L1_distance])\n",
    "optimizer = Adam(0.00006)\n",
    "# optimizer = 'adam'\n",
    "siamese_net.compile(loss=['binary_crossentropy'], optimizer=optimizer, metrics=['accuracy'])\n",
    "siamese_net.summary()\n",
    "\n",
    "a1 = np.linalg.norm(siamese_net.layers[2].layers[13].get_weights()[0])\n",
    "a2 = np.linalg.norm(siamese_net.layers[3].layers[13].get_weights()[0])\n",
    "print(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 164025 samples, validate on 2025 samples\n",
      "Epoch 1/100\n",
      "164025/164025 [==============================] - 142s 865us/step - loss: 0.6934 - acc: 0.5004 - val_loss: 0.6929 - val_acc: 0.5146\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50914 to 0.51457, saving model to /home/amplifier/home/NEW_DL/weights/Siam3EEGnet_wts.h5\n",
      "Epoch 3/100\n",
      " 76260/164025 [============>.................] - ETA: 1:15 - loss: 0.6934 - acc: 0.5035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 862us/step - loss: 0.6933 - acc: 0.5004 - val_loss: 0.6932 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.51457\n",
      "Epoch 6/100\n",
      " 47240/164025 [=======>......................] - ETA: 1:40 - loss: 0.6933 - acc: 0.4982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 142s 863us/step - loss: 0.6933 - acc: 0.5010 - val_loss: 0.6934 - val_acc: 0.5022\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.51457\n",
      "Epoch 8/100\n",
      "152520/164025 [==========================>...] - ETA: 9s - loss: 0.6932 - acc: 0.5021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 857us/step - loss: 0.6924 - acc: 0.5165 - val_loss: 0.6951 - val_acc: 0.4909\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.51457\n",
      "Epoch 11/100\n",
      "119680/164025 [====================>.........] - ETA: 37s - loss: 0.6817 - acc: 0.5665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 861us/step - loss: 0.5740 - acc: 0.7038 - val_loss: 0.6630 - val_acc: 0.6365\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.53926 to 0.63654, saving model to /home/amplifier/home/NEW_DL/weights/Siam3EEGnet_wts.h5\n",
      "Epoch 14/100\n",
      " 66300/164025 [===========>..................] - ETA: 1:23 - loss: 0.5229 - acc: 0.7447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 860us/step - loss: 0.3755 - acc: 0.8367 - val_loss: 0.8731 - val_acc: 0.5694\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.63654\n",
      "Epoch 17/100\n",
      " 34720/164025 [=====>........................] - ETA: 1:50 - loss: 0.3472 - acc: 0.8521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 859us/step - loss: 0.2909 - acc: 0.8786 - val_loss: 1.0154 - val_acc: 0.6163\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63654\n",
      "Epoch 19/100\n",
      "164025/164025 [==============================] - 141s 859us/step - loss: 0.2598 - acc: 0.8932 - val_loss: 1.0604 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63654\n",
      "Epoch 20/100\n",
      "  3380/164025 [..............................] - ETA: 2:17 - loss: 0.2552 - acc: 0.8956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 858us/step - loss: 0.2195 - acc: 0.9109 - val_loss: 1.1903 - val_acc: 0.5872\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.63654\n",
      "Epoch 22/100\n",
      "109800/164025 [===================>..........] - ETA: 46s - loss: 0.2022 - acc: 0.9191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 857us/step - loss: 0.1728 - acc: 0.9321 - val_loss: 1.2949 - val_acc: 0.5669\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.63654\n",
      "Epoch 25/100\n",
      " 88140/164025 [===============>..............] - ETA: 1:04 - loss: 0.1621 - acc: 0.9368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 858us/step - loss: 0.1450 - acc: 0.9439 - val_loss: 1.4329 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.63654\n",
      "Epoch 28/100\n",
      " 54920/164025 [=========>....................] - ETA: 1:33 - loss: 0.1441 - acc: 0.9443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164025/164025 [==============================] - 141s 861us/step - loss: 0.1335 - acc: 0.9488 - val_loss: 1.4385 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.63654\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=20, mode='min')\n",
    "checkpointer = ModelCheckpoint(filepath='/home/amplifier/home/NEW_DL/weights/Siam3EEGnet_wts.h5',\n",
    "                               verbose=1,\n",
    "                               monitor='val_acc',\n",
    "                               save_best_only=True)\n",
    "\n",
    "train_history = siamese_net.fit([X_train[:,0,:,:,None], X_train[:,1,:,:,None]], Y_train,\n",
    "                epochs=100,\n",
    "                batch_size=20,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                validation_data=([X_test[:,0,:,:,None], X_test[:,1,:,:,None]], Y_test),\n",
    "                callbacks=[checkpointer, early_stopping])\n",
    "\n",
    "# model.save('/home/amplifier/home/NEW_DL/models/Siam3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.load_weights('/home/amplifier/home/NEW_DL/weights/Siam3_wts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(np.array(history.losses))\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.title('AdaDelta')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8f6f024cab2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'correct'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "rng = np.random.choice(y_train.shape[0], 195, replace=False)\n",
    "prediction = []\n",
    "for i in rng:\n",
    "    pred = siamese_net.predict([x_train[None,i,0,:,:,None], x_train[None,i,1,:,:,None]])\n",
    "    prediction.append(pred)\n",
    "    acc = 'correct' if np.round(pred)==y_train[i] else \"\"\n",
    "    train_acc.append(1 if np.round(pred)==y_train[i] else 0)\n",
    "#     print(i, pred, np.round(pred), y_train[i], acc)\n",
    "print('Train Accuracy', np.mean(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-eb4bddf1570e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m190\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "rng = np.random.choice(y_test.shape[0], 190, replace=False)\n",
    "prediction = []\n",
    "for i in rng:\n",
    "    pred = siamese_net.predict([x_test[None,i,0,:,:,None], x_test[None,i,1,:,:,None]])\n",
    "    prediction.append(pred)\n",
    "    acc = 'correct' if np.round(pred)==y_train[i] else \"\"\n",
    "    test_acc.append(1 if np.round(pred)==y_train[i] else 0)\n",
    "#     print(i, pred, np.round(pred), y_test[i], acc)\n",
    "print('Test Accuracy', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [[0.9992372]] [1] [1] 0\n",
      "7 [[0.00024588]] [1] [1] 1\n",
      "21 [[0.46680015]] [0] [0] 1\n",
      "14 [[0.01244232]] [1] [0] 0\n",
      "36 [[0.04232696]] [1] [0] 0\n",
      "29 [[0.99990094]] [1] [0] 1\n",
      "19 [[0.1772979]] [1] [1] 1\n",
      "12 [[0.9069365]] [1] [1] 0\n",
      "37 [[0.7378922]] [0] [1] 1\n",
      "36 [[0.29272014]] [1] [1] 1\n",
      "15 [[0.04256096]] [0] [0] 1\n",
      "28 [[0.53658324]] [0] [0] 0\n",
      "29 [[0.9999231]] [1] [0] 1\n",
      "18 [[0.00088351]] [0] [1] 0\n",
      "30 [[0.9805331]] [0] [0] 0\n",
      "10 [[0.9360994]] [0] [0] 0\n",
      "18 [[0.99991226]] [0] [0] 0\n",
      "44 [[0.00152636]] [1] [0] 0\n",
      "37 [[0.9978452]] [0] [0] 0\n",
      "47 [[0.78717244]] [0] [0] 0\n",
      "2 [[0.9994961]] [0] [1] 1\n",
      "12 [[0.8994222]] [1] [1] 0\n",
      "41 [[0.7775418]] [1] [1] 0\n",
      "36 [[0.99999964]] [1] [1] 0\n",
      "35 [[0.00529279]] [1] [1] 1\n",
      "0 [[0.9932267]] [0] [0] 0\n",
      "8 [[0.9999838]] [0] [1] 1\n",
      "28 [[0.00052391]] [0] [1] 0\n",
      "8 [[0.9998846]] [0] [1] 1\n",
      "18 [[0.9999815]] [0] [1] 1\n",
      "12 [[0.46604905]] [1] [0] 0\n",
      "3 [[0.8300947]] [1] [1] 0\n",
      "25 [[0.00095356]] [1] [1] 1\n",
      "43 [[0.9842917]] [1] [1] 0\n",
      "11 [[8.524662e-05]] [0] [0] 1\n",
      "3 [[0.9992888]] [1] [1] 0\n",
      "44 [[0.9985189]] [1] [1] 0\n",
      "27 [[0.0054677]] [0] [1] 0\n",
      "36 [[0.00521404]] [1] [1] 1\n",
      "42 [[0.9952041]] [1] [0] 1\n",
      "4 [[0.96593416]] [0] [0] 0\n",
      "38 [[0.9997105]] [0] [1] 1\n",
      "2 [[0.9987847]] [0] [0] 0\n",
      "4 [[0.9698879]] [0] [0] 0\n",
      "39 [[5.106873e-05]] [0] [0] 1\n",
      "29 [[0.4841347]] [1] [0] 0\n",
      "13 [[1.5899724e-06]] [1] [0] 0\n",
      "19 [[0.00050936]] [1] [1] 1\n",
      "15 [[0.04388002]] [0] [0] 1\n",
      "1 [[0.4396221]] [1] [1] 1\n",
      "Validation accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "val_acc = []\n",
    "for k in range(len(Y_val)):\n",
    "    i = np.random.randint(len(Y_val))\n",
    "    j = np.random.randint(len(Y_val))\n",
    "    pred = siamese_net.predict([X_val[None,i,:,:,None], X_val[None,j,:,:,None]])\n",
    "    correct = 1 if Y_val[i]==Y_val[j] and np.round(pred)==0 or Y_val[i]!=Y_val[j] and np.round(pred)==1  else 0\n",
    "    val_acc.append(correct)\n",
    "    print(i, pred, Y_val[i], Y_val[j], correct)\n",
    "print('Validation accuracy:', np.mean(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 1, 60, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 60, 128)        500       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4, 60, 128)        16        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 8, 1, 128)         480       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 1, 128)         32        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 8, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 8, 1, 32)          192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 1, 32)          32        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 8, 1, 4)           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 8, 1, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,318\n",
      "Trainable params: 1,278\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
    "             dropoutRate = 0.25, kernLength = 64, F1 = 4, \n",
    "             D = 2, F2 = 8, dropoutType = 'Dropout'):\n",
    "    \"\"\" Keras Implementation of EEGNet (https://arxiv.org/abs/1611.08024)\n",
    "\n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.     \n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 4, F2 = F1 * D. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (1, Chans, Samples))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (1, Chans, Samples),\n",
    "                                   use_bias = False, data_format='channels_first')(input1)\n",
    "    block1       = BatchNormalization(axis = 1)(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.), data_format='channels_first')(block1)\n",
    "    block1       = BatchNormalization(axis = 1)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4), data_format='channels_first')(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False,\n",
    "                                   padding = 'same',\n",
    "                                   data_format='channels_first')(block1)\n",
    "    block2       = BatchNormalization(axis = 1)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8), data_format='channels_first')(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense', \n",
    "                         kernel_constraint = max_norm(0.25))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "model  = EEGNet(nb_classes = 2,\n",
    "                Chans = 60,\n",
    "                Samples = 128,\n",
    "                kernLength = 125)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79]\n",
      "[80 81 82 83 84 85 86 87 88 89]\n",
      "[90 91 92 93 94 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "def TrainTestVal_Split(leng, traintest, testval):\n",
    "    leng = 100\n",
    "    x = np.arange(leng)\n",
    "    train_id, test_id, val_id = np.split(\n",
    "        x,[np.round(leng*traintest).astype(int),\n",
    "           np.round(leng*testval).astype(int)])\n",
    "    return train_id, test_id, val_id\n",
    "\n",
    "# train_id, test_id, val_id = TrainTestVal_Split(100, 0.8, 0.9)\n",
    "# print(train_id)\n",
    "# print(test_id)\n",
    "# print(val_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[418]\n",
      "success\n",
      "[437]\n",
      "success\n",
      "[75]\n",
      "success\n",
      "[405]\n",
      "success\n",
      "[96]\n",
      "success\n",
      "[216]\n",
      "success\n",
      "[193]\n",
      "success\n",
      "[246]\n",
      "success\n",
      "[144]\n",
      "success\n",
      "[155]\n",
      "success\n",
      "[162]\n",
      "success\n",
      "[191]\n",
      "success\n",
      "[258]\n",
      "success\n",
      "[309]\n",
      "success\n",
      "[126]\n",
      "success\n",
      "[299]\n",
      "success\n",
      "[52]\n",
      "success\n",
      "[340]\n",
      "success\n",
      "[156]\n",
      "success\n",
      "[281]\n",
      "success\n",
      "[121]\n",
      "success\n",
      "[163]\n",
      "success\n",
      "[107]\n",
      "success\n",
      "[104]\n",
      "success\n",
      "[279]\n",
      "success\n",
      "[10]\n",
      "success\n",
      "[264]\n",
      "success\n",
      "[376]\n",
      "success\n",
      "[428]\n",
      "success\n",
      "[101]\n",
      "success\n",
      "[217]\n",
      "success\n",
      "[168]\n",
      "success\n",
      "[39]\n",
      "success\n",
      "[303]\n",
      "success\n",
      "[304]\n",
      "success\n",
      "[61]\n",
      "success\n",
      "[18]\n",
      "success\n",
      "[305]\n",
      "success\n",
      "[212]\n",
      "success\n",
      "[272]\n",
      "success\n",
      "[188]\n",
      "success\n",
      "[67]\n",
      "success\n",
      "[86]\n",
      "success\n",
      "[354]\n",
      "success\n",
      "[411]\n",
      "success\n",
      "[439]\n",
      "success\n",
      "[291]\n",
      "success\n",
      "[82]\n",
      "success\n",
      "[365]\n",
      "success\n",
      "[149]\n",
      "success\n",
      "[238]\n",
      "success\n",
      "[59]\n",
      "success\n",
      "[146]\n",
      "success\n",
      "[209]\n",
      "success\n",
      "[170]\n",
      "success\n",
      "[298]\n",
      "success\n",
      "[140]\n",
      "success\n",
      "[268]\n",
      "success\n",
      "[307]\n",
      "success\n",
      "[100]\n",
      "success\n",
      "[420]\n",
      "success\n",
      "[192]\n",
      "success\n",
      "[23]\n",
      "success\n",
      "[416]\n",
      "success\n",
      "[175]\n",
      "success\n",
      "[80]\n",
      "success\n",
      "[438]\n",
      "success\n",
      "[345]\n",
      "success\n",
      "[399]\n",
      "success\n",
      "[447]\n",
      "success\n",
      "[359]\n",
      "success\n",
      "[445]\n",
      "success\n",
      "[444]\n",
      "success\n",
      "[377]\n",
      "success\n",
      "[390]\n",
      "success\n",
      "[250]\n",
      "success\n",
      "[374]\n",
      "success\n",
      "[85]\n",
      "success\n",
      "[157]\n",
      "success\n",
      "[371]\n",
      "success\n",
      "[247]\n",
      "success\n",
      "[98]\n",
      "success\n",
      "[352]\n",
      "success\n",
      "[159]\n",
      "success\n",
      "[327]\n",
      "success\n",
      "[311]\n",
      "success\n",
      "[321]\n",
      "success\n",
      "[48]\n",
      "success\n",
      "[134]\n",
      "success\n",
      "[45]\n",
      "success\n",
      "[15]\n",
      "success\n",
      "[114]\n",
      "success\n",
      "[38]\n",
      "success\n",
      "[331]\n",
      "success\n",
      "[316]\n",
      "success\n",
      "[368]\n",
      "success\n",
      "[95]\n",
      "success\n",
      "[68]\n",
      "success\n",
      "[357]\n",
      "success\n",
      "[5]\n",
      "success\n",
      "[150]\n",
      "success\n",
      "[277]\n",
      "success\n",
      "[92]\n",
      "success\n",
      "[91]\n",
      "success\n",
      "[130]\n",
      "success\n",
      "[446]\n",
      "success\n",
      "[154]\n",
      "success\n",
      "[60]\n",
      "success\n",
      "[11]\n",
      "success\n",
      "[369]\n",
      "success\n",
      "[412]\n",
      "success\n",
      "[391]\n",
      "success\n",
      "[220]\n",
      "success\n",
      "[40]\n",
      "success\n",
      "[125]\n",
      "success\n",
      "[346]\n",
      "success\n",
      "[266]\n",
      "success\n",
      "[20]\n",
      "success\n",
      "[424]\n",
      "success\n",
      "[417]\n",
      "success\n",
      "[128]\n",
      "success\n",
      "[373]\n",
      "success\n",
      "[152]\n",
      "success\n",
      "[83]\n",
      "success\n",
      "[115]\n",
      "success\n",
      "[50]\n",
      "success\n",
      "[103]\n",
      "success\n",
      "[245]\n",
      "success\n",
      "[72]\n",
      "success\n",
      "[4]\n",
      "success\n",
      "[241]\n",
      "success\n",
      "[322]\n",
      "success\n",
      "[169]\n",
      "success\n",
      "[105]\n",
      "success\n",
      "[441]\n",
      "success\n",
      "[136]\n",
      "success\n",
      "[214]\n",
      "success\n",
      "[223]\n",
      "success\n",
      "[106]\n",
      "success\n",
      "[206]\n",
      "success\n",
      "[6]\n",
      "success\n",
      "[199]\n",
      "success\n",
      "[434]\n",
      "success\n",
      "[26]\n",
      "success\n",
      "[27]\n",
      "success\n",
      "[400]\n",
      "success\n",
      "[392]\n",
      "success\n",
      "[178]\n",
      "success\n",
      "[19]\n",
      "success\n",
      "[347]\n",
      "success\n",
      "[3]\n",
      "success\n",
      "[421]\n",
      "success\n",
      "[242]\n",
      "success\n",
      "[153]\n",
      "success\n",
      "[261]\n",
      "success\n",
      "[138]\n",
      "success\n",
      "[116]\n",
      "success\n",
      "[124]\n",
      "success\n",
      "[33]\n",
      "success\n",
      "[172]\n",
      "success\n",
      "[301]\n",
      "success\n",
      "[436]\n",
      "success\n",
      "[73]\n",
      "success\n",
      "[360]\n",
      "success\n",
      "[265]\n",
      "success\n",
      "[313]\n",
      "success\n",
      "[263]\n",
      "success\n",
      "[275]\n",
      "success\n",
      "[269]\n",
      "success\n",
      "[406]\n",
      "success\n",
      "[442]\n",
      "success\n",
      "[167]\n",
      "success\n",
      "[225]\n",
      "success\n",
      "[119]\n",
      "success\n",
      "[333]\n",
      "success\n",
      "[290]\n",
      "success\n",
      "[90]\n",
      "success\n",
      "[203]\n",
      "success\n",
      "[278]\n",
      "success\n",
      "[410]\n",
      "success\n",
      "[81]\n",
      "success\n",
      "[53]\n",
      "success\n",
      "[71]\n",
      "success\n",
      "[55]\n",
      "success\n",
      "[36]\n",
      "success\n",
      "[147]\n",
      "success\n",
      "[213]\n",
      "success\n",
      "[21]\n",
      "success\n",
      "[342]\n",
      "success\n",
      "[102]\n",
      "success\n",
      "[379]\n",
      "success\n",
      "[398]\n",
      "success\n",
      "[289]\n",
      "success\n",
      "[141]\n",
      "success\n",
      "[179]\n",
      "success\n",
      "[387]\n",
      "success\n",
      "[335]\n",
      "success\n",
      "[44]\n",
      "success\n",
      "[28]\n",
      "success\n",
      "[312]\n",
      "success\n",
      "[284]\n",
      "success\n",
      "[380]\n",
      "success\n",
      "[388]\n",
      "success\n",
      "[394]\n",
      "success\n",
      "[227]\n",
      "success\n",
      "[184]\n",
      "success\n",
      "[88]\n",
      "success\n",
      "[415]\n",
      "success\n",
      "[431]\n",
      "success\n",
      "[160]\n",
      "success\n",
      "[252]\n",
      "success\n",
      "[367]\n",
      "success\n",
      "[164]\n",
      "success\n",
      "[64]\n",
      "success\n",
      "[427]\n",
      "success\n",
      "[132]\n",
      "success\n",
      "[430]\n",
      "success\n",
      "[117]\n",
      "success\n",
      "[228]\n",
      "success\n",
      "[389]\n",
      "success\n",
      "[12]\n",
      "success\n",
      "[393]\n",
      "success\n",
      "[423]\n",
      "success\n",
      "[348]\n",
      "success\n",
      "[24]\n",
      "success\n",
      "[324]\n",
      "success\n",
      "[171]\n",
      "success\n",
      "[257]\n",
      "success\n",
      "[186]\n",
      "success\n",
      "[113]\n",
      "success\n",
      "[123]\n",
      "success\n",
      "[432]\n",
      "success\n",
      "[185]\n",
      "success\n",
      "[13]\n",
      "success\n",
      "[32]\n",
      "success\n",
      "[200]\n",
      "success\n",
      "[51]\n",
      "success\n",
      "[255]\n",
      "success\n",
      "[402]\n",
      "success\n",
      "[180]\n",
      "success\n",
      "[295]\n",
      "success\n",
      "[69]\n",
      "success\n",
      "[161]\n",
      "success\n",
      "[361]\n",
      "success\n",
      "[166]\n",
      "success\n",
      "[280]\n",
      "success\n",
      "[308]\n",
      "success\n",
      "[449]\n",
      "success\n",
      "[326]\n",
      "success\n",
      "[205]\n",
      "success\n",
      "[294]\n",
      "success\n",
      "[395]\n",
      "success\n",
      "[142]\n",
      "success\n",
      "[131]\n",
      "success\n",
      "[234]\n",
      "success\n",
      "[350]\n",
      "success\n",
      "[201]\n",
      "success\n",
      "[259]\n",
      "success\n",
      "[386]\n",
      "success\n",
      "[239]\n",
      "success\n",
      "[253]\n",
      "success\n",
      "[120]\n",
      "success\n",
      "[229]\n",
      "success\n",
      "[414]\n",
      "success\n",
      "[190]\n",
      "success\n",
      "[34]\n",
      "success\n",
      "[237]\n",
      "success\n",
      "[385]\n",
      "success\n",
      "[84]\n",
      "success\n",
      "[111]\n",
      "success\n",
      "[8]\n",
      "success\n",
      "[174]\n",
      "success\n",
      "[118]\n",
      "success\n",
      "[409]\n",
      "success\n",
      "[182]\n",
      "success\n",
      "[57]\n",
      "success\n",
      "[62]\n",
      "success\n",
      "[270]\n",
      "success\n",
      "[37]\n",
      "success\n",
      "[122]\n",
      "success\n",
      "[419]\n",
      "success\n",
      "[425]\n",
      "success\n",
      "[292]\n",
      "success\n",
      "[317]\n",
      "success\n",
      "[77]\n",
      "success\n",
      "[97]\n",
      "success\n",
      "[293]\n",
      "success\n",
      "[338]\n",
      "success\n",
      "[65]\n",
      "success\n",
      "[343]\n",
      "success\n",
      "[332]\n",
      "success\n",
      "[16]\n",
      "success\n",
      "[240]\n",
      "success\n",
      "[110]\n",
      "success\n",
      "[74]\n",
      "success\n",
      "[165]\n",
      "success\n",
      "[204]\n",
      "success\n",
      "[151]\n",
      "success\n",
      "[403]\n",
      "success\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-834-dae8bb9c8bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mxx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mhit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2165\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(xx_train.shape[0]):\n",
    "    hit = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if np.linalg.norm(X[i,:,:] - xx_train[j,0,:,:])==0:\n",
    "            hit.append(i)\n",
    "            print(hit)\n",
    "            print('success' if np.linalg.norm(Y[i] - yy_train[j])==0 else 'FAIL!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before augmenting (324, 2, 60, 128)\n",
      "(1620, 2, 60, 128)\n",
      "(1620, 1, 60, 128)\n",
      "(1620, 1, 60, 128)\n",
      "After augmenting (1620, 2, 60, 128)\n",
      "(1620, 2, 60, 128)\n",
      "yy_train_aug (1620, 2)\n",
      "\n",
      "After augmenting:\n",
      " (1620, 2, 60, 128) \n",
      " (1620, 2)\n"
     ]
    }
   ],
   "source": [
    "def train_augment(xx_train, yy_train):\n",
    "    print('Before augmenting', xx_train.shape)\n",
    "    temp_xx = np.concatenate([xx_train, xx_train, xx_train, xx_train, xx_train], axis=0)\n",
    "    print(temp_xx.shape)\n",
    "    temp_xx_0 = temp_xx[:,0,:,:]\n",
    "    temp_xx_0 = temp_xx_0.reshape(temp_xx_0.shape + (1,)).transpose(0,3,1,2)\n",
    "    print(temp_xx_0.shape)\n",
    "\n",
    "    temp_xx_1 = temp_xx[:,1,:,:]\n",
    "    np.random.shuffle(temp_xx_1)\n",
    "    temp_xx_1 = temp_xx_1.reshape(temp_xx_1.shape + (1,)).transpose(0,3,1,2)\n",
    "    print(temp_xx_1.shape)\n",
    "\n",
    "    xx_train_aug = np.concatenate([temp_xx_0, temp_xx_1], axis=1)\n",
    "    print('After augmenting', xx_train_aug.shape)\n",
    "    print(xx_train_aug.shape)\n",
    "\n",
    "    yy_train_aug = np.concatenate([yy_train, yy_train, yy_train, yy_train, yy_train], axis=0)\n",
    "    print('yy_train_aug', yy_train_aug.shape)\n",
    "    return xx_train_aug, yy_train_aug\n",
    "\n",
    "if AUGMENT==True:\n",
    "    xx_train, yy_train = train_augment(xx_train, yy_train)\n",
    "    print('\\nAfter augmenting:\\n', xx_train.shape,'\\n', yy_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = [],[]\n",
    "for i in range(len(X)):\n",
    "    if np.array_equal(Y[i],np.array([0,1])):\n",
    "        a.append(i)\n",
    "    if np.array_equal(Y[i],np.array([1,0])):\n",
    "        b.append(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX_a\t (225, 2, 60, 128)\n",
      "XX_b\t (225, 2, 60, 128)\n",
      "XX\t (450, 2, 60, 128)\n",
      "\n",
      "XX_trai\t (324, 2, 60, 128)\n",
      "XX_test\t (81, 2, 60, 128)\n",
      "XX_val\t (45, 2, 60, 128)\n",
      "yy_trai\t (324, 2)\n",
      "yy_test\t (81, 2)\n",
      "yy_val\t (45, 2)\n",
      "\n",
      "If you use RANDOM SEED, check if you generate the same numbers every time:\n",
      "[291 144  54 215 210 167 184 442 273  96  62 420 255  76 278  86 270 152\n",
      " 122 325  48 326 264 110 436  31 410 214 361 257 357  73 407 205 115  97\n",
      " 172 303 285   9 242  59 366 119 118 348 267 141  26 345 447 437 224 446\n",
      " 178 189 359 245 107 262 108 330 432 272 364 250 279 346  80 388 439 206\n",
      " 171  33  29 164 258 235 336  13  74  45 406 415 434 317 183 374  92 193\n",
      " 208 219 428  99 225 368  51 256 342  19 394 237  44 360 132 192 315  11\n",
      " 296 414 431 424 169 367   4 412 133 283  68 234 397   5 395 328 101 288\n",
      "  40 165 248 112 449 307 148 308 377 157 309 338 204 320 339 127  64 221\n",
      " 135 378 401  77 159 353 236 138 381  93  25 408 337 413 117 260  58 444\n",
      "  79 266 306 318  47 386 227 251  72 292 380 203 387 176 179 399  55 198\n",
      " 123  70 438 261  36 284 150  60   8 196 441  21  41  82  63  85  12 313\n",
      " 389 271  27 423 400  69 147 168 295 268 411 425 191 393 409 290 358  81\n",
      "  32 201 376 116 402 244 429 143 222 324 182 254 427 247 422 124 104   0\n",
      "  66 289 263 158 103  56 259 146 341 344 299  95 293 207 240 362 109 153\n",
      " 329 298  22 355  75 404 443 331 311  37 213 416 333 276 310 120 239 175\n",
      " 275 321  15 391 161 156  30 121 177 160 130 233  14 220 281 134 419 105\n",
      " 332  53 145 216 327 417 316 113 356 323  49 371 249  98 142  20  89  71\n",
      " 398  28  18   7 243 154 229 194 287 369 162 231 253 382 246 190 166 365]\n",
      "[269  34 373 200 319 418 372 277 128 197 312  38 209  83 195 140 218 370\n",
      " 379 151   3 343 131  39  50  46 232 106 403  17 352   2 445  35 375 302\n",
      " 347 390 170 282  94 217  16 340  67 430 228 392 354 349  87 137 322 334\n",
      " 435 102 212  57 363 125  84 351 350 199 405 186 139 136 286 173  23 280\n",
      "  42 185  90 265 226  52 180 335 384]\n",
      "[300  43 211 188 129 238  88 174 294 230 149 305  24 163 385  91  65 274\n",
      "  78 426  61 433 100 114 297 304 202 223   6 155 181 126 314 440 448 187\n",
      " 301 252   1 383  10 421 396 111 241]\n"
     ]
    }
   ],
   "source": [
    "XX_a = np.zeros([len(a),2,X.shape[1],X.shape[2]])\n",
    "XX_b = np.zeros([len(b),2,X.shape[1],X.shape[2]])\n",
    "XX = np.zeros([len(a)+len(b),2,X.shape[1],X.shape[2]])\n",
    "\n",
    "YY_a = np.zeros([len(a),2])\n",
    "YY_b = np.zeros([len(b),2])\n",
    "YY = np.zeros([len(b)+len(b),2])\n",
    "\n",
    "XX_a[:,0,:,:] = X[a,:,:]\n",
    "XX_a[:,1,:,:] = X[np.random.permutation(a),:,:]\n",
    "YY_a = Y[a]\n",
    "XX_b[:,0,:,:] = X[b,:,:]\n",
    "XX_b[:,1,:,:] = X[np.random.permutation(b),:,:]\n",
    "YY_b = Y[b]\n",
    "\n",
    "XX = np.concatenate([XX_a, XX_b], axis=0)\n",
    "YY = np.concatenate([YY_a, YY_b], axis=0)\n",
    "\n",
    "print('XX_a\\t', XX_a.shape)\n",
    "print('XX_b\\t', XX_b.shape)\n",
    "print('XX\\t', XX.shape)\n",
    "\n",
    "train_id, test_id, val_id = train_test_val(XX,YY, 0.2, 0.1, shuffle=SHUFFLE)\n",
    "\n",
    "xx_train = XX[train_id,:,:,:]\n",
    "yy_train = YY[train_id]\n",
    "\n",
    "xx_test = XX[test_id,:,:,:]\n",
    "yy_test = YY[test_id]\n",
    "\n",
    "xx_val = XX[val_id,:,:,:]\n",
    "yy_val = YY[val_id]\n",
    "\n",
    "print('\\nXX_trai\\t', xx_train.shape)\n",
    "print('XX_test\\t', xx_test.shape)\n",
    "print('XX_val\\t', xx_val.shape)\n",
    "print('yy_trai\\t', yy_train.shape)\n",
    "print('yy_test\\t', yy_test.shape)\n",
    "print('yy_val\\t', yy_val.shape)\n",
    "\n",
    "print('\\nIf you use RANDOM SEED, check if you generate the same numbers every time:')\n",
    "print(train_id)\n",
    "print(test_id)\n",
    "print(val_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "569px",
    "left": "637.074px",
    "right": "20px",
    "top": "126.989px",
    "width": "603px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
